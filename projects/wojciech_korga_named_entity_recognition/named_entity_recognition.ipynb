{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER",
      "provenance": [],
      "collapsed_sections": [
        "UKOPAkKsMdHP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcYhQlzluy59",
        "colab_type": "text"
      },
      "source": [
        "#Named entity recognition\n",
        "\n",
        "Named entity recognition is a natural language processing task of information extraction that seeks to locate and classify proper names and other word categories in natural language texts, such as résumés, scientific papers, news articles or text messages.\n",
        "The most common classification goals are:\n",
        "- finding personal data such as name or address of the person mentioned in text\n",
        "- marking numerical values, dates, quantities etc. that may contain useful information\n",
        "- finding names of organizations, countries, cities etc.\n",
        "The output of a classifying algorithm may be later used by other algorithms to perform various data mining tasks.\n",
        "\n",
        "Example:\n",
        "\n",
        "Unstructured input:\n",
        "Jim bought 300 shares of Acme Corp. in 2006.\n",
        "\n",
        "Output:\n",
        "**{Person: Jim}** bought **{Number: 300}** shares of **{Organization: Acme Corp.}** in **{Time: 2006}**\n",
        "\n",
        "The goal of this project is to create a NER classifier, that would be able to detect some pre-defined number of categories.\n",
        "The training data will be derived from one of many corpora available online, that provide pre-categorized sentences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5unylKhujgZ",
        "colab_type": "text"
      },
      "source": [
        "#Intuitions\n",
        "The simplest idea for a classfier would be to create a probability matrix for words from training set, where we would store probabilities of a word belonging to each category.\n",
        "While it may work for very distinct words like surnames, it would most likely fail to recognize many entities, especially these not present in training data. But apart from the word itself, a lot of useful information can be obtained from the context the word is used in:\n",
        "\n",
        "**Nice** to meet you!\n",
        "\n",
        "**Nice** is a beautiful city.\n",
        "\n",
        "Having information about surrounding words, part of speech and capitalization migth have a significant effect on classifier's performance.\n",
        "\n",
        "##Bayesian approach\n",
        "Naive Bayes algorithm proved itself to be a reliable classifier in many NLP-related task such as spam recognition.\n",
        "But usually it uses long sequences of words to calculate the most possible class for a whole text, while this time the task is to predict categories for single words.\n",
        "\n",
        "The general idea is to use context of the word to create a sequence of values, which can be later used by the NB algorithm to calculate conditional probability:\n",
        "\n",
        "\\begin{equation*}\n",
        "  p(Category | Word) = p(Category | POS) p(Category | Previous) p(Category | Next)...\n",
        "\\end{equation*} \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uppbVkAfvEpX",
        "colab_type": "text"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeeuGJeYwVvM",
        "colab_type": "text"
      },
      "source": [
        "The classfier will be based on [**Annotated Corpus for Named Entity Recognition** by Abhinav Walia](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
        "\n",
        "Every entry, apart from the word and its category contains information about its part of speech.\n",
        "\n",
        "The original dataset contains 9 categories, but since some of them seem to be very poorly represented, we will use only the 5 most popular:\n",
        "- GEO - Geographical Entity\n",
        "- GPE - Geopolitical Entity\n",
        "- ORG - Organization\n",
        "- PER - Person\n",
        "- O - None\n",
        "\n",
        "Every category can have two forms\n",
        "- B-Category - beginning of an entity\n",
        "- I-Category - end of an entity\n",
        "\n",
        "So **\"citizen of European Union\"**\n",
        "\n",
        "should be tagged as \n",
        "\n",
        "**[O, O, B-ORG, I-ORG]**\n",
        "\n",
        "\n",
        "Unfortunately the dataset has a very annoying format, so we have to convert it to a more convenient one, and save it as a new file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uB721lNGqQO",
        "colab_type": "code",
        "outputId": "8f986271-b9c4-436c-d375-54ed62be54b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "pd.read_csv(\"ner_dataset.csv\",encoding = \"ISO-8859-1\").head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS    Tag\n",
              "0  Sentence: 1      Thousands  NNS      O\n",
              "1          NaN             of   IN      O\n",
              "2          NaN  demonstrators  NNS      O\n",
              "3          NaN           have  VBP      O\n",
              "4          NaN        marched  VBN      O\n",
              "5          NaN        through   IN      O\n",
              "6          NaN         London  NNP  B-geo\n",
              "7          NaN             to   TO      O\n",
              "8          NaN        protest   VB      O\n",
              "9          NaN            the   DT      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6j_qnqoGxAB",
        "colab_type": "text"
      },
      "source": [
        "After changes it has a more convenient form:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90lsNO61GwPX",
        "colab_type": "code",
        "outputId": "2fd973ab-f393-4dc3-c371-f652b1b0fbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "pd.read_csv(\"corpus_4_categories.csv\").head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>pos</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
              "      <td>O O O O O O B-GEO O O O O O B-GEO O O O O O B-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               tags\n",
              "0           0  ...  O O O O O O B-GEO O O O O O B-GEO O O O O O B-...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E79vNd7m0pk8",
        "colab_type": "text"
      },
      "source": [
        "#Creating NB model\n",
        "Every entry in the dataset\n",
        "\n",
        "**{word, part_of_speech, category}**\n",
        "\n",
        "is going to be transformed to a vector\n",
        "\n",
        "**{lowercase_word, part_of_speech, previous_word, next_word, is_capitalized, category}**\n",
        "\n",
        "Next, for every part of the information vector we will create a probability matrix, containing conditional probabilities\n",
        "\\begin{equation*}\n",
        "  p(Value | Category)\n",
        "\\end{equation*} \n",
        "for every possible value.\n",
        "\n",
        "So in the end there will be 5 separate probability matrices.\n",
        "\n",
        "We will also use Laplace Smoothing and save probabilities as logarithmic values for the reasons discussed in Assignment 2\n",
        "\n",
        "For convenience, the results will be saved as a JSON \"model\" file, to avoid having to repeat the calculations.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5_7jTuU7mjG",
        "colab_type": "text"
      },
      "source": [
        "#Classifier\n",
        "The classifier itself is a standard NB classfier, based on a general idea of multiplying probabilities for every independent variable, and choosing the most probable category.\n",
        "To decide the category of an entity it will sum 5 log probability vectors and choose the most possible class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2055eHUKyHA",
        "colab_type": "text"
      },
      "source": [
        "#Testing\n",
        "First we will test our classfier on a test data derived from the training dataset.\n",
        "We will split dataset in a ratio of 4 to 1, train the classifier on the bigger part and validate results with the other.\n",
        "\n",
        "We will also create a model trained on full data and validate it with an independent NER dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-m_wAHXLEiP",
        "colab_type": "text"
      },
      "source": [
        "#Validation and comparing results to other classifiers\n",
        "\n",
        "We will test both models, using a popular 4-category [NLTK](https://www.nltk.org/) classfier, and 4-category [Standford NER](https://nlp.stanford.edu/software/CRF-NER.shtml) as benchmarks for our predictions.\n",
        "\n",
        "As a measure, we will use the F1 score for every category, which is the harmonic mean of the precision and recall and reaches its best value at 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1teYSYphLZeV",
        "colab_type": "text"
      },
      "source": [
        "##Validating the train-test model\n",
        "\n",
        "In this case we will use only our NB classifier and NLTK, because categories in Stanford models don't match the ones used in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "61be7bf7-6e57-45af-8317-d77837752961",
        "id": "ReX3W52BLsVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "df = pd.DataFrame(np.c_[nltk_scores,nb_scores], index=targets, columns=['NLTK','NB'])\n",
        "df.plot.bar()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEPCAYAAABShj9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAWNElEQVR4nO3df5Bd5X3f8fdXP/CmmN+7EAbJWcUW\nCTRDAG8giTvFjh2PsDPQBpeB/HDaca22QKb8ikduGSITeWoDtqgHJbUIxmBsE0xoRwwYYTsY1Tio\nLEaxQTKxTGlYEiIhYwwoKqj59o97Fy6ru7tH0t17zn30fs3scM85j+79rvTwuc99zjnPjcxEkjT4\n5tVdgCSpNwx0SSqEgS5JhTDQJakQBrokFWJBXS88PDyco6Ojdb28JA2kRx555LnMHOl2rLZAHx0d\nZXx8vK6Xl6SBFBH/Z7pjTrlIUiEMdEkqxKyBHhGfi4htEfHYNMcjIj4TEVsj4rsRcWrvy5QkzabK\nHPrngeuBW6Y5fiawtP1zOvAn7f/utVdffZWJiQl27dq1L398IA0NDbFo0SIWLlxYdymSBtysgZ6Z\nGyJidIYmZwO3ZGtRmIci4vCIODYz/25vi5mYmOCQQw5hdHSUiNjbPz5wMpMdO3YwMTHBkiVL6i5H\n0oDrxRz6ccDTHdsT7X17bdeuXRx11FEHRJgDRARHHXXUAfWJRNLc6etJ0YhYHhHjETG+ffv26dr0\ns6TaHWi/r6S504tAfwZY3LG9qL1vD5m5NjPHMnNsZKTrdfGSpH3UixuL1gEXRcRttE6GvrAv8+fd\njK64uxdP85qnPvH+WdtEBJdeeimf+tSnALj22mt56aWXWLlyJStXruTNb34zl19+OQDbtm3jve99\nLwDPPvss8+fPZ/KNauPGjRxzzDH8+Mc/BuCuu+7i8ssv5+tf/zqLFy/u8sqStH9mDfSI+DLwTmA4\nIiaAPwQWAmTmfwPuAd4HbAV2Av9mrorthze96U3ceeedfPSjH2V4eHjGtkcffTSbNm0C4IorrmB4\neJiLL74YgN27d7/Wbv369VxyySV87WtfM8ylwlQZeFYZTPZClatczp/leAIX9qyimi1YsIDly5ez\nevVqPv7xj+/3891///1ccMEF3HvvvV7JImlO1baWS5NdeOGFnHTSSXzkIx/Zr+fZuXMn55xzDhs2\nbGDp0qU9qk7SwFl5WMV2L+zXy3jrfxeHHnooH/zgB/nMZz6zX88zNDTE6aefzk033dSjyiRpegb6\nNC6++GJuvPFGXn755X1+jnnz5nHHHXfwrW99i6uvvrqH1UnSngz0aRx55JGce+653Hjjjfv1PAcf\nfDB33303N910EzfffHOPqpOkPTV6Dr1fZ4anc9lll3H99de/Yd+qVau47rrrXtuemJiY9XmGh4e5\n9957OeOMMxgeHub976/395JUpmhdpNJ/Y2NjOfULLrZs2cIJJ5xQSz11OlB/b6kElS5bHPqtak9W\n4aRoRDySmWPdjjnlIkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgrR6OvQK69/UPn5Kl0SNOPyuTfc\ncAMjIyPs2rWLd73rXaxZs4Z583xflFQ/k2iKyeVzn3vuua7HL7nkEjZt2sTmzZv53ve+xwMPPNDn\nCiWpOwN9is7lc2fyyiuvsGvXLo444og+VSZJMzPQu7jwwgv54he/yAsv7DlFs3r1ak4++WSOPfZY\njj/+eE4++eQaKpSkPRnoXcy0fO7klMu2bdt4+eWXue2222qoUJL2ZKBPY7blcxcuXMiyZcvYsGFD\nnyuTpO4M9GnMtnxuZvLggw/y1re+tc+VSVJ3Db9scf++jml/dVs+d/Xq1dx66628+uqrnHTSSVxw\nwQU1VSdJb9TsQK/BSy+99NrjY445hp07d762PXktuiQ1kVMuklQIA12SCtG4QK/rG5TqcqD9vpLm\nTqMCfWhoiB07dhwwIZeZ7Nixg6GhobpLkVSARp0UXbRoERMTE2zfvr3uUvpmaGiIRYsW1V2GpAI0\nKtAXLlzIkiVL6i5DkgZSowK9KFWW/q35OntJZTHQJZXlAB5MNeqkqCRp3xnoklQIA12SCmGgS1Ih\nKp0UjYhlwH8F5gN/mpmfmHL8LcDNwOHtNisy854e1zq9A/gkiCRNmnWEHhHzgTXAmcCJwPkRceKU\nZlcAt2fmKcB5wB/3ulBJ0syqTLmcBmzNzCcz8xXgNuDsKW0SOLT9+DDgb3tXoiSpiipTLscBT3ds\nTwCnT2mzErgvIn4fOBh4T0+qkyRV1quToucDn8/MRcD7gC9ExB7PHRHLI2I8IsYPpPVaJKkfqgT6\nM8Diju1F7X2dPgTcDpCZfwkMAcNTnygz12bmWGaOjYyM7FvFkqSuqgT6w8DSiFgSEQfROum5bkqb\nvwHeDRARJ9AKdIfgktRHswZ6Zu4GLgLWA1toXc3yeERcFRFntZtdBnw4Iv4K+DLwr/NAWdRckhqi\n0nXo7WvK75my78qOx5uBd/S2NEnS3vBOUUkqhMvnql5V7vIF7/SVKnCELkmFMNAlqRAGuiQVwkCX\npEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkq\nhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY\n6JJUCANdkgqxoO4CpMZZeVjFdi/MbR3SXjLQJQ2M0RV3z9rmqaE+FNJQlaZcImJZRDwREVsjYsU0\nbc6NiM0R8XhEfKm3ZUqSZjPrCD0i5gNrgF8HJoCHI2JdZm7uaLMU+Cjwjsx8PiKOnquCJUndVRmh\nnwZszcwnM/MV4Dbg7CltPgysycznATJzW2/LlCTNpkqgHwc83bE90d7X6Xjg+Ih4MCIeiohl3Z4o\nIpZHxHhEjG/fvn3fKpYkddWryxYXAEuBdwLnAzdExOFTG2Xm2swcy8yxkZGRHr20JAmqBfozwOKO\n7UXtfZ0mgHWZ+Wpm/m/gr2kFvCSpT6oE+sPA0ohYEhEHAecB66a0+R+0RudExDCtKZgne1inJGkW\nswZ6Zu4GLgLWA1uA2zPz8Yi4KiLOajdbD+yIiM3A/cAfZOaOuSpakrSnSjcWZeY9wD1T9l3Z8TiB\nS9s/kqQauJaLJBXCQJekQhjoklQIF+c6kFRZRdAVBKWB5QhdkgphoEtSIQx0SSqEgS5JhTDQJakQ\nBrokFcJAl6RCGOiSVAgDXZIK4Z2ihRhdcfesbZ4a6kMhkmrjCF2SCmGgS1IhDHRJKoRz6JozzutL\n/WWgS9p3LsncKE65SFIhDHRJKoSBLkmFcA5dUlee1B48jtAlqRAGuiQVwkCXpEIY6JJUCANdkgph\noEtSIQx0SSqEgS5JhTDQJakQBrokFaJSoEfEsoh4IiK2RsSKGdqdExEZEWO9K1GSVMWsgR4R84E1\nwJnAicD5EXFil3aHAP8R2NjrIiVJs6syQj8N2JqZT2bmK8BtwNld2v0R8ElgVw/rkyRVVCXQjwOe\n7tieaO97TUScCizOzBmXZ4uI5RExHhHj27dv3+tiJUnT2++TohExD/g0cNlsbTNzbWaOZebYyMjI\n/r60JKlDlfXQnwEWd2wvau+bdAjwC8A3IwLgp4F1EXFWZo73qtAmcZ1oSU1UZYT+MLA0IpZExEHA\necC6yYOZ+UJmDmfmaGaOAg8BxYa5JDXVrIGembuBi4D1wBbg9sx8PCKuioiz5rpASVI1lb6CLjPv\nAe6Zsu/Kadq+c//LkiTtLe8UlaRCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJek\nQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEJU+sYiSQ2w8rAKbV6Y+zrUWI7Q\nJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12S\nCmGgS1IhDHRJKkSlQI+IZRHxRERsjYgVXY5fGhGbI+K7EfGNiPiZ3pcqSZrJrIEeEfOBNcCZwInA\n+RFx4pRmjwJjmXkScAdwda8LlSTNrMoI/TRga2Y+mZmvALcBZ3c2yMz7M3Nne/MhYFFvy5QkzaZK\noB8HPN2xPdHeN50PAV/tdiAilkfEeESMb9++vXqVkqRZ9fSkaET8DjAGXNPteGauzcyxzBwbGRnp\n5UtL0gGvypdEPwMs7the1N73BhHxHuA/A2dk5v/tTXmSpKqqjNAfBpZGxJKIOAg4D1jX2SAiTgE+\nC5yVmdt6X6YkaTazBnpm7gYuAtYDW4DbM/PxiLgqIs5qN7sGeDPwlYjYFBHrpnk6SdIcqTLlQmbe\nA9wzZd+VHY/f0+O6JEl7yTtFJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWp\nEAa6JBXCQJekQhjoklSISotzSaUYXXH3rG2eGupDIdIccIQuSYUw0CWpEAa6JBXCQJekQhjoklQI\nA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIRq9HnqVtavB9asl\nCRyhS1IxDHRJKkSjp1ykA4FTi+oVR+iSVIhKgR4RyyLiiYjYGhEruhx/U0T8Wfv4xogY7XWhkqSZ\nzRroETEfWAOcCZwInB8RJ05p9iHg+cx8G7Aa+GSvC5UkzazKCP00YGtmPpmZrwC3AWdPaXM2cHP7\n8R3AuyMielemJGk2kZkzN4j4ALAsM/9te/t3gdMz86KONo+120y0t3/YbvPclOdaDixvb/4c8ESP\nfo9h4LlZW/WXNVVjTdU1sS5rqqaXNf1MZo50O9DXq1wycy2wttfPGxHjmTnW6+fdH9ZUjTVV18S6\nrKmaftVUZcrlGWBxx/ai9r6ubSJiAXAYsKMXBUqSqqkS6A8DSyNiSUQcBJwHrJvSZh3we+3HHwD+\nImeby5Ek9dSsUy6ZuTsiLgLWA/OBz2Xm4xFxFTCemeuAG4EvRMRW4Ee0Qr+fej6N0wPWVI01VdfE\nuqypmr7UNOtJUUnSYPBOUUkqhIEuSYVwcS5JmgMRMQS8rb25NTN3zfVrOkJXI0TEW+quQWWpq09F\nxIKIuBqYoHUH/S3A0xFxdUQsnMvXHshAj4ijI+JjEXFH++djEXFMjfXc3vH4k1OO3df/iporIn4l\nIj4QEUe3t0+KiC8BD9ZYU6P6U7sm+1RFDexT1wBHAksy8+2ZeSrwVuBw4Nq5fOGBC/SIeAeta+Oh\n9c53S/vxxvaxOiztePzrU451vUV3rkXEhyLiDzq2n4mIn0TEixHx72uq6Rrgc8A5wN0RsQq4D9jI\nG/8O+1lTE/sT2Keq1tS4PgX8BvDhzHxxckdm/gT4D8D75vSVM3OgfoCHgFO67D8Z2FhTTd/p9rjb\ndh9rehg4qmP70fZ/h4AHaqppMzDUfnwE8BIwWkctHTU1rj9N7Tf2qYHrU3+9L8d68TOIJ0UPzcxH\np+7MzE0RcUgdBQH/JCJOofWJ56faj6P981M11RSZ2bn8wlcAMnNXRNRV065snxjKzOcj4geZ+VRN\ntUxqYn8C+1RVTexTmyPig5l5S+fOiPgd4Ptz+cIDd2NRRGwBfjUzn5+y/0jg25n58zXU9E1g2r/I\nzHxX/6ppiYit2Vqffur+ebTOuP9sDTX9GNjQseufd25n5lk11NS4/tR+/W9in6pSUxP71HHAncA/\nAI+0d4/ReiP+l5k5dS2s3r32AAb6cuDDwOXAd9q7307rSzU+l5mfrau2JomIPwZ+lJlXTNm/ChjO\nzL7PeUbEGTMdz8wH+lXLJPtTdfapvRMRvwb80/bm5sz8xpy/5qAFOkBE/AbwEVp/WUlrHu2azLyr\npnqW0jqz/Tbge8Dlc/kuXLGmg4E/BX4J+Kv27l8ExplywqaPNR2arZND3Y69JTP/pt81tV+7Uf2p\nXZN9qlpNjexTdRnIQG+aiPiftK6O2ACcBfxKZv5mvVW1RMTP8sZRwg9rrOU72bqEi4j4Rma+u9sx\n2af2ohb7VIdBvGyxidfnHpKZN2TmE5l5DTBaUx17yNZXB97V/vlhRBwfETfUVE7n1xIeOcOxvmlo\nfwL7VFWN61N1GrhAp4HX5wJDEXFKRJwaEafSviqhY7vv2jdX3BcRj0XEqog4NiL+HPgLWlMKdchp\nHnfb7pcm9iewT1XVxD5Vm0G8bHGmf6S6/gH/Dvh0x/azHdsJ/FrfK4IbgD8B/hI4E9hE6zbk384+\nrCkxjaMj4lJaI6fJx7S36wrPJvYnsE9V1cQ+VZuBm0OPiO8D59P6dHEr8Fu8fn3urZl5Qo3lNUZE\nbMrMkzu2n6zjsrIpNf3hTMcz82P9qmWS/ak6+1TzDWKg3z/T8Zquzz0UOCYzf9De/le8fvPH+sz8\n+xpqmgyqyXnEL/J6WJGZ35nmj865iBjOzEZ8K3sT+xPYp/ZWk/pUnQYu0JsoItbSugnl8+3trcBX\naf0PuLum63NnCqrMzL5/ZG9fHngT8Crwj8C5mfntftcxCOxT1din3mjgAr2hI5dHgVOz/ZcZEY9m\n5intx9/KzH/W75qaKCK+S+t/uO9HxOnA1Zk5440hfaipcf2pXYd9qoIm9qk6DeJJ0WuBbwM/aG//\nF14fufwqUMeqbwvyje+Mv9vx+PB+FzMpWsuJXsjr1ww/DqzJzG01lbQ7M78PkJkba14rZVIT+xPY\np6pqYp+qzSAG+i8B/65j+8XM/H1ojVzqKYl/jIifzsxnATLzsXY9x9H6GNh30Vr69UvA53l9Sdi3\nA/8rIn47M+tYK7rzKoQ9tjPz013+zFxrYn8C+1RVTexTtRnEQG/iyOUa4K6IuAyYXLnvVFqjv2tq\nqulTwL/IN64kuC4i/jvwWeD0Gmq6AThkhu06NLE/gX2qqib2qdoMYqA3buSSmbdGxHPAKl5fD+Rx\n4MrM/GodNdHAZWEbeglZ4/pTuw77VAUN7VO1GcRAb+LIhcy8F7i3rtfvIiLiiOy+LGxj7hBuwHob\njexPYJ/aVw3oU7UZuEBv6MhlDw3oVKuB+yKi27Kwq2urak+1rrcxKP0J7FN74YBbw2XSwAU6NHLk\n0k3dQbU2Iv4W+CPeuCzsqqxxWdgu7q67gAHpT2Cfqqr2PlWXgbsOvZsGjFz2EBGrcsoXAWhPETEM\n7MgGdcQm9iewT2l2jZn32k9N/Ih1XUQ0qq6IqO3W7Pbr/3JEfDMi7myvHPgY8Bjw9xGxrM7apmjU\nv9ukJoZ5A/rUixHxky4/L0ZE1y++KNlATrl0UetHrIj4ZeATwI9ofRz9AjAMzIvWl8U25eN83UF1\nPfCfgMNoLbl6ZmY+FBE/D3yZ5kx71P6RPSJepPtqj0HrNvtD+1zSdOqeBjpgL1HsppRAvy4iosaP\n7QZVNQsy8z6AiLgqMx8CaN+2XW9lHZowEh6goKq7T6nDwE25NPRj+4LMvC8zvwI82xlUNdUznbqn\ngTqv6/6HKcdqeTP2I/v+acKbn143iCP0Jo6GmxhUTZwG+sV2SAatb+CZDMwAhmqoZ5BGwrUboGmg\nA9bAXeUSHYvsR8SW7PgCgs4V6fpc0/8DXqYdVMDOyUPAUGYurKGmcV5/41vLlDe+Ov6eJM2tQRyh\nN240nJnz63jdWQzEfLWk3hnEQG/cx/aGatwbn6S5NXBTLqqmidNAkuaWgS5JhRi4yxYlSd0Z6JJU\nCANdkgphoEtSIf4/BXVPEbpo3GIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obcKjv18GVtY",
        "colab_type": "text"
      },
      "source": [
        "As we can see the NB classfier achieved much higher scores for almost every category\n",
        "\n",
        "While the results might give the impression that NLTK is much worse than our classifier, we should remeber that the NER tagging is not arbitrary, and interpretation of certain entities relies havily on traning data. And since we are testing on data similar to training set of our classfier, it has a great advantage over NLTK.\n",
        "\n",
        "We can show the problem with a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tngPxat4ewjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3e976dc-5170-4319-8e0b-638a9a275495"
      },
      "source": [
        "nb_predict(\"President Trump is visiting Poland\",model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-PER', 'I-PER', 'O', 'O', 'B-GEO']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMcOwRfAfVou",
        "colab_type": "code",
        "outputId": "870c2a35-59d7-48ec-96ab-ff5ba5b75fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from_nltk_categories(nltk_predict(\"President Trump is visiting Poland\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-PER', 'O', 'O', 'B-GPE'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5AMAiztahXZ",
        "colab_type": "text"
      },
      "source": [
        "Since there is no strict definition of a named entity both classifications can be seen as correct - NLTK pays attention only to the surname, while our NB classfier tags \"President Trump\" as a single two-word entity.\n",
        "\n",
        "Which one will be marked as correct depends solely on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwPQIfkkL4zx"
      },
      "source": [
        "##Validating full model on an independent dataset\n",
        "The previous test have shown that NB classfier can perform better than NLTK for the test set derived from the same dataset as the training data, while also showing that the results may be significantly biased.\n",
        "\n",
        "But now let's see how will they perform on an independent dataset. This time we will use all three classifiers.\n",
        "\n",
        "We will use a [WikiNER dataset](https://github.com/dice-group/FOX/tree/master/input/Wikiner)\n",
        "\n",
        "Unfortunately after running tests on the dataset and viewing some tagged entities, it seems that the categories and entity interpretation used in WikiNER don't match the ones used in NLTK and NB classfiers, which leads to terrible results for both of them.\n",
        "\n",
        "Instead we will just focus on recognising **if** the word should be tagged as entity.\n",
        "\n",
        "So this time there will be only two categories:\n",
        "- ENT - the word should be tagged\n",
        "- O - it should not\n",
        "\n",
        "So both the training data and classifiers output will be converted to this \"binary\" model.\n",
        "\n",
        "Once again the format of data is not very convenient for our classifiers to work with:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Rm4WWSh_-5",
        "colab_type": "code",
        "outputId": "08a1a97d-852f-4f6a-f736-d45850561438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "with open('aij-wikiner-en-wp3_10000','r+') as file:\n",
        "  print(file.readline())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The|DT|I-MISC Oxford|NNP|I-MISC Companion|NNP|I-MISC to|TO|I-MISC Philosophy|NNP|I-MISC says|VBZ|O ,|,|O \"|LQU|O there|EX|O is|VBZ|O no|DT|O single|JJ|O defining|VBG|O position|NN|O that|IN|O all|DT|O anarchists|NNS|O hold|VBP|O ,|,|O and|CC|O those|DT|O considered|VBN|O anarchists|NNS|O at|IN|O best|JJS|O share|NN|O a|DT|O certain|JJ|O family|NN|O resemblance|NN|O .|.|O \"|RQU|O\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3nP4bBKjB0W",
        "colab_type": "text"
      },
      "source": [
        "So we have to convert it and reduce the number of categories to 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yHmP5pxi5b_",
        "colab_type": "code",
        "outputId": "8cd29e05-5cc5-4173-e44d-62f846a375d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "wikiner_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Oxford Companion to Philosophy says , \" th...</td>\n",
              "      <td>ENT ENT ENT ENT ENT O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the end , for anarchist historian Daniel Gu...</td>\n",
              "      <td>O O O O O O O ENT ENT O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From this climate William Godwin developed wha...</td>\n",
              "      <td>O O O ENT ENT O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Godwin was , according to Peter Kropotkin , \" ...</td>\n",
              "      <td>ENT O O O O ENT ENT O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The first to describe himself as an anarchist ...</td>\n",
              "      <td>O O O O O O O O O ENT ENT O O ENT O O O O O O ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence                                               tags\n",
              "0  The Oxford Companion to Philosophy says , \" th...  ENT ENT ENT ENT ENT O O O O O O O O O O O O O ...\n",
              "1  In the end , for anarchist historian Daniel Gu...  O O O O O O O ENT ENT O O O O O O O O O O O O ...\n",
              "2  From this climate William Godwin developed wha...              O O O ENT ENT O O O O O O O O O O O O\n",
              "3  Godwin was , according to Peter Kropotkin , \" ...  ENT O O O O ENT ENT O O O O O O O O O O O O O ...\n",
              "4  The first to describe himself as an anarchist ...  O O O O O O O O O ENT ENT O O ENT O O O O O O ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnHLU6b7YlUB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The results for all three classifiers are following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "22eac0ee-7294-42e0-ccf7-6fbbadbd8066",
        "id": "l1l8Vvc3MCWe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "df = pd.DataFrame(np.c_[nltk_scores,nb_scores,st_scores], index=targets, columns=['NLTK','NB','Stanford'])\n",
        "df.plot.bar()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAECCAYAAADuGCyPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgphoEtSIf4dynsKAuxXqiQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9R0plA9zyNb",
        "colab_type": "text"
      },
      "source": [
        "In this case the results ale less favourable for our NB classfier.\n",
        "\n",
        "But all of them seem to behave in similar way. While they slightly differ within ENT category, we can see that score for 'O' is above 90% in all cases.\n",
        "The scores for ENT are also relatively high.\n",
        "It means that each of them can with high probability say if a word is a named entity or if it isn't.\n",
        "\n",
        "Stanford NER reached the highest score, but it's worth noting that when NB and NLTK were able to tag 10000 sentences in less than a minute, Stanford tagger needed more than **5 hours** to perform this task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2Wg_v3n5APW",
        "colab_type": "text"
      },
      "source": [
        "#Conclusions\n",
        "\n",
        "It has been shown that a NER classfier based on a \"simple\" Naive Bayes algorithm can achieve results comparable to other classifiers.\n",
        "\n",
        "Once again the NB proved itself to be a reliable classfier with many applications in NLP field, despite being based on \"naive\" assumptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIwhOE3AFGcN",
        "colab_type": "text"
      },
      "source": [
        "#Further development\n",
        "\n",
        "The classifier created above can be upgraded, using more careful data analysis.\n",
        "\n",
        "Using more information such as part of speech of surrounding words, longer n-grams or lemmatization of words might have a positive impact on results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKOPAkKsMdHP",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZUVLphRvBkg",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzxTsXVEHZJB",
        "colab_type": "code",
        "outputId": "8d988f88-01a2-49d8-87a5-9a1ad506f451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqmTye8NSyVo",
        "colab_type": "code",
        "outputId": "b99fd7b4-1cc4-47dd-cad1-748033922e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Standard IPython notebook imports\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "import httpimport\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook\n",
        "import scipy.stats as sstats\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "import csv as csv\n",
        "import sklearn.decomposition\n",
        "import sklearn.svm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "import json\n",
        "from nltk.tag import StanfordNERTagger"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpwUDqSJ6DFc",
        "colab_type": "text"
      },
      "source": [
        "###Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2BEKaaJDY7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_df = pd.read_csv(\"ner_dataset.csv\",encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgHC_xhZWwdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_df = full_df.fillna(method='ffill')\n",
        "full_df['Tag'] = np.char.upper(list(full_df['Tag']))\n",
        "full_df['Tag'][np.isin(full_df['Tag'],['B-ART','B-EVE','B-NAT'])] = 'O'\n",
        "full_df['Tag'][np.isin(full_df['Tag'],['I-ART','I-EVE','I-NAT'])] = 'O'\n",
        "full_df['Tag'][np.isin(full_df['Tag'],['I-TIM','B-TIM'])] = 'O'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uu7tO-Ax9Xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sentences(sentence_df, full_df):  \n",
        "  index =0\n",
        "  prev = None\n",
        "  sentence =[]\n",
        "  pos = []\n",
        "  tags = [] \n",
        "  for i in range(len(full_df)):\n",
        "    row = full_df.iloc[i]\n",
        "    s_num = row[0]\n",
        "    word = row[1]\n",
        "    ps = row[2]\n",
        "    ner = row[3]\n",
        "    if i>0 and prev!=s_num:\n",
        "      sentence_df.loc[index] = (\" \".join(sentence),\" \".join(pos),\" \".join(tags))\n",
        "      index+=1\n",
        "      sentence =[]\n",
        "      pos = []\n",
        "      tags = [] \n",
        "    \n",
        "    sentence.append(word)\n",
        "    pos.append(ps)\n",
        "    tags.append(ner)\n",
        "    prev = s_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOPfA6BV1tgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_df = pd.DataFrame(columns=['sentence', 'pos', 'tags'])\n",
        "create_sentences(sentence_df, full_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxNrumiLNFBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_df.to_csv(r'corpus_4_categories.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "655pOS4w0g1A",
        "colab_type": "text"
      },
      "source": [
        "##Creating Naive Bayes model from data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlqeJQPPCkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put_in_dict(key,dct,target, targets):\n",
        "  dct.setdefault(key, np.ones(len(targets))*0.5)\n",
        "  dct[key]+=(targets==target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdJtu8j8eQD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_dictionary(dct,target_counts):\n",
        "  vls = np.array(list(dct.values()))\n",
        "  vls/target_counts\n",
        "  vls = vls/np.sum(vls,axis=0)\n",
        "  vls = np.log(vls+1E-100)\n",
        "  return dict(zip(dct.keys(), vls.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVD5f6yDC6W9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(sentence_df, save_path):\n",
        "  targets, target_counts = np.unique(np.hstack(np.chararray.split(np.array(sentence_df['tags'],\\\n",
        "                                                                           dtype='str'))),\\\n",
        "                                     return_counts=True)\n",
        "  target_counts = target_counts/(len(target_counts))\n",
        "  word_dict={}\n",
        "  pos_dict={}\n",
        "  prev_dict={}\n",
        "  next_dict={}\n",
        "  is_title={}\n",
        "  for index,row in sentence_df.iterrows():\n",
        "    words = row[1].split()\n",
        "    pos = row[2].split()\n",
        "    tags = row[3].split()\n",
        "    if len(tags)!=len(words):\n",
        "        continue\n",
        "    for i in range(len(words)):\n",
        "      put_in_dict(words[i].lower(),word_dict,tags[i],targets)\n",
        "      put_in_dict(pos[i],pos_dict,tags[i],targets)\n",
        "      put_in_dict(words[i].istitle(),is_title,tags[i],targets)\n",
        "      if i==0:\n",
        "        put_in_dict('$$$NONE$$$',prev_dict,tags[i],targets)\n",
        "      else:\n",
        "        put_in_dict(words[i-1].lower(),prev_dict,tags[i],targets)\n",
        "      if i==len(words)-1:\n",
        "        put_in_dict('$$$NONE$$$',next_dict,tags[i],targets)\n",
        "      else:\n",
        "        put_in_dict(words[i+1].lower(),next_dict,tags[i],targets)\n",
        "  \n",
        "  json_dict = {}\n",
        "  json_dict['words'] = normalize_dictionary(word_dict,target_counts)\n",
        "  json_dict['pos'] = normalize_dictionary(pos_dict,target_counts)\n",
        "  json_dict['prev'] = normalize_dictionary(prev_dict,target_counts)\n",
        "  json_dict['next'] = normalize_dictionary(next_dict,target_counts)\n",
        "  json_dict['title'] = normalize_dictionary(is_title,target_counts)\n",
        "  json_dict['targets'] = targets.tolist()\n",
        "  with open(save_path, 'w') as fout:\n",
        "    json.dump(json_dict , fout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADlAZm-57SqH",
        "colab_type": "text"
      },
      "source": [
        "##Naive Bayes classfier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2--J6dDtiOvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def naive_bayes(elem, model):\n",
        "  dicts = list(model.values())[:-1]\n",
        "  targets =  list(model.values())[-1:][0]\n",
        "  log_probs=np.zeros(len(targets))\n",
        "  for i in range(len(elem)):\n",
        "    dct = dicts[i]\n",
        "    log_probs+=np.array(dct.get(elem[i],np.ones(len(targets))*-0.69314718056))\n",
        "  exps = np.exp(log_probs)\n",
        "  return targets[np.argmax(exps)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HZ33SN88iXj",
        "colab_type": "text"
      },
      "source": [
        "##Creating models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZCpud0t8oLW",
        "colab_type": "text"
      },
      "source": [
        "##Train-test model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y68IZNllraZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_df = pd.read_csv('corpus_4_categories.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA4bjTLajgfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = sentence_df.head(np.int(len(sentence_df)*0.8))\n",
        "test_df = sentence_df.tail(len(sentence_df)-len(train_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIn9C3VERNiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_model(train_df,\"4_categories_train_model.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPMI_Aa09mHq",
        "colab_type": "text"
      },
      "source": [
        "##Full model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGAhdBsyt5DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_model(sentence_df,\"4_categories_full_model.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV8WpLmV91DV",
        "colab_type": "text"
      },
      "source": [
        "##Validation and comparing results to other classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0XaDg8L95e6",
        "colab_type": "text"
      },
      "source": [
        "###Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBphaGgGc17I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_model(path):\n",
        "  with open(path, 'r') as f:\n",
        "    model = json.load(f)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9fEe4J9_Ukg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def from_nltk_categories(nltk_preds):\n",
        "  nltk_preds = np.array(nltk_preds)\n",
        "  nltk_preds[nltk_preds=='B-FACILITY'] = 'O'\n",
        "  nltk_preds[nltk_preds=='I-FACILITY'] = 'O'\n",
        "  nltk_preds[nltk_preds=='B-GSP'] = 'B-GPE'\n",
        "  nltk_preds[nltk_preds=='I-GSP'] = 'I-GPE'\n",
        "  nltk_preds[nltk_preds=='B-LOCATION'] = 'B-GEO'\n",
        "  nltk_preds[nltk_preds=='I-LOCATION'] = 'I-GEO'\n",
        "  nltk_preds[nltk_preds=='B-ORGANIZATION'] = 'B-ORG'\n",
        "  nltk_preds[nltk_preds=='I-ORGANIZATION'] = 'I-ORG'\n",
        "  nltk_preds[nltk_preds=='B-PERSON'] = 'B-PER'\n",
        "  nltk_preds[nltk_preds=='I-PERSON'] = 'I-PER'\n",
        "  return nltk_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmeCIjQ_9-1U",
        "colab_type": "text"
      },
      "source": [
        "###Validating the train-test model\n",
        "\n",
        "In this case we will use only our NB classifier and NLTK, because categories in Stanford models don't match the ones used in our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9tV1X1GF8kE",
        "colab_type": "text"
      },
      "source": [
        "####Calculating predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSOXXJqEETE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = read_model(\"4_categories_train_model.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfw0p9_NvkUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_preds = []\n",
        "nb_actual = []\n",
        "for index, row in test_df.iterrows():\n",
        "  words = row[1].split()\n",
        "  pos = row[2].split()\n",
        "  tags = row[3].split()\n",
        "  if len(tags)!=len(words):\n",
        "    continue\n",
        "  for i in range(len(words)):\n",
        "    if i==0:\n",
        "      prev = '$$$NONE$$$'\n",
        "    else:\n",
        "      prev = words[i-1].lower()\n",
        "    if i==len(words)-1:\n",
        "      nxt = '$$$NONE$$$'\n",
        "    else:\n",
        "      nxt= words[i+1].lower()\n",
        "    element = (words[i].lower(),pos[i],prev,nxt,words[i].istitle())\n",
        "    nb_preds.append(naive_bayes(element,model))\n",
        "    nb_actual.append(tags[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B4i1BEGYeo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk_preds = []\n",
        "nltk_actual = []\n",
        "for index, row in test_df.iterrows():\n",
        "  words = row[1]\n",
        "  tags = row[3].split()\n",
        "  tokens = nltk.word_tokenize(words)\n",
        "  if(len(tags)!=len(tokens)):\n",
        "    continue\n",
        "  tagged_words = nltk.pos_tag(nltk.word_tokenize(words))\n",
        "  nltk_unformatted_prediction = nltk.ne_chunk(tagged_words)\n",
        "  multiline_string = nltk.chunk.tree2conllstr(nltk_unformatted_prediction)\n",
        "  listed_pos_and_ne = multiline_string.split()\n",
        "  nltk_preds.extend(listed_pos_and_ne[2::3])\n",
        "  nltk_actual.extend(tags)\n",
        "nltk_preds = from_nltk_categories(nltk_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkk2Szw1GBti",
        "colab_type": "text"
      },
      "source": [
        "####Comparing results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCu-NwqnGQDt",
        "colab_type": "text"
      },
      "source": [
        "We will now compare the F1 scores of both classfiers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVH999KrBmxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "nltk_rep = classification_report(nltk_actual, nltk_preds,target_names=list(model.values())[-1:][0], output_dict=True)\n",
        "nb_rep = classification_report(nb_actual, nb_preds,target_names=list(model.values())[-1:][0], output_dict=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7qzuc1QCqqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets = list(model.values())[-1:][0]\n",
        "nltk_scores = []\n",
        "for scores in list(nltk_rep.values())[:9]:\n",
        "  nltk_scores.append(scores['f1-score'])\n",
        "nb_scores = []\n",
        "for scores in list(nb_rep.values())[:9]:\n",
        "  nb_scores.append(scores['f1-score'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk5UcBMqD0r6",
        "colab_type": "code",
        "outputId": "61be7bf7-6e57-45af-8317-d77837752961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "df = pd.DataFrame(np.c_[nltk_scores,nb_scores], index=targets, columns=['NLTK','NB'])\n",
        "df.plot.bar()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEPCAYAAABShj9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCANdkgphoEtSIf4/BXVPEbpo3GIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UHRIQX2eQXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faL4da0e-NhE",
        "colab_type": "text"
      },
      "source": [
        "###Validating full model on an independent dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO_bVHP0Ha0t",
        "colab_type": "text"
      },
      "source": [
        "####Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4hmz8wDHeW5",
        "colab_type": "text"
      },
      "source": [
        "The data need some preprocessing as the format is not very convenient for both classfiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTkvRL6JHX9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wikiner_df = pd.DataFrame(columns=['sentence', 'tags'])\n",
        "index = 0\n",
        "with open('aij-wikiner-en-wp3_10000','r') as file:\n",
        "  for line in file:\n",
        "    tokens = line.split()\n",
        "    sentence = []\n",
        "    tags = []\n",
        "    for t in tokens:\n",
        "      t = t.split(\"|\")\n",
        "      sentence.append(t[0])\n",
        "      if t[2] != 'O':\n",
        "        tags.append('ENT')\n",
        "      else:\n",
        "        tags.append(t[2])\n",
        "    wikiner_df.loc[index] = (\" \".join(sentence),\" \".join(tags))\n",
        "    index+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeuwAyjKg_hs",
        "colab_type": "text"
      },
      "source": [
        "We will need to convert our predictions to \"binary\" categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGX2WfHuhFdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_categories(preds):\n",
        "  preds = np.array(preds)\n",
        "  preds[preds!='O'] = 'ENT'\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGi3X-vLijh-",
        "colab_type": "text"
      },
      "source": [
        "####Calculating predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22XuLjkjen-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nb_predict(sent, model):\n",
        "  tokens = nltk.pos_tag(nltk.word_tokenize(sent))\n",
        "  preds = []\n",
        "  for i in range(len(tokens)):\n",
        "    word = tokens[i][0].lower()\n",
        "    pos = tokens[i][1].strip('$')\n",
        "    is_title = str(word.istitle()).lower()\n",
        "    if i==0:\n",
        "      prev = '$$$NONE$$$'\n",
        "    else:\n",
        "      prev = tokens[i-1][0].lower()\n",
        "    if i==len(tokens)-1:\n",
        "      nxt = '$$$NONE$$$'\n",
        "    else:\n",
        "      nxt = tokens[i+1][0].lower()\n",
        "    elem = (word,pos,prev,nxt,is_title)\n",
        "    pred = naive_bayes(elem, model)\n",
        "    preds.append(pred)\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjH8uRNYfC62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = read_model(\"4_categories_full_model.json\")\n",
        "nb_preds = []\n",
        "nb_actual = []\n",
        "\n",
        "for index, row in wikiner_df.iterrows():\n",
        "  words = row[0]\n",
        "  tags = row[1].split()\n",
        "  preds = nb_predict(words,model)\n",
        "  if(len(preds)!=len(tags)):\n",
        "    continue\n",
        "  nb_preds.extend(preds)\n",
        "  nb_actual.extend(tags)\n",
        "nb_preds = convert_categories(nb_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqY42TpEfG9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_predict(words):\n",
        "  tagged_words = nltk.pos_tag(nltk.word_tokenize(words))\n",
        "  nltk_unformatted_prediction = nltk.ne_chunk(tagged_words)\n",
        "  multiline_string = nltk.chunk.tree2conllstr(nltk_unformatted_prediction)\n",
        "  listed_pos_and_ne = multiline_string.split()\n",
        "  return listed_pos_and_ne[2::3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSWNHccBgqY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk_preds = []\n",
        "nltk_actual = []\n",
        "for index, row in wikiner_df.iterrows():\n",
        "  words = row[0]\n",
        "  tags = row[1].split()\n",
        "  tokens = nltk.word_tokenize(words)\n",
        "  if(len(tags)!=len(tokens)):\n",
        "    continue\n",
        "  nltk_preds.extend(nltk_predict(words))\n",
        "  nltk_actual.extend(tags)\n",
        "nltk_preds = convert_categories(nltk_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPrPRbGEjeRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_preds = []\n",
        "st_actual = []\n",
        "st = StanfordNERTagger('english.conll.4class.distsim.crf.ser.gz','stanford-ner.jar',encoding='utf-8')\n",
        "for index, row in wikiner_df.iterrows():\n",
        "  words = row[0]\n",
        "  tags = row[1].split()\n",
        "  tokens = nltk.word_tokenize(words)\n",
        "  if(len(tags)!=len(tokens)) or len(tags)==0:\n",
        "    continue\n",
        "  tagged_words = st.tag(tokens) \n",
        "  st_preds.extend(np.array(tagged_words)[:,1].tolist())\n",
        "  st_actual.extend(tags)\n",
        "st_preds = convert_categories(st_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Bmm7K9jC1F",
        "colab_type": "text"
      },
      "source": [
        "####Comparing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A__TYi68jFrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "targets = np.unique(nltk_actual)\n",
        "nltk_rep = classification_report(nltk_preds, nltk_actual,target_names=targets, output_dict=True)\n",
        "nb_rep = classification_report(nb_preds, nb_actual,target_names=targets, output_dict=True)\n",
        "st_rep = classification_report(st_preds, st_actual,target_names=targets, output_dict=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LEF0W58jH2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk_scores = []\n",
        "for scores in list(nltk_rep.values())[:2]:\n",
        "  nltk_scores.append(scores['f1-score'])\n",
        "nb_scores = []\n",
        "for scores in list(nb_rep.values())[:2]:\n",
        "  nb_scores.append(scores['f1-score'])\n",
        "st_scores = []\n",
        "for scores in list(st_rep.values())[:2]:\n",
        "  st_scores.append(scores['f1-score'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWlQgaExjKDP",
        "colab_type": "code",
        "outputId": "22eac0ee-7294-42e0-ccf7-6fbbadbd8066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "df = pd.DataFrame(np.c_[nltk_scores,nb_scores,st_scores], index=targets, columns=['NLTK','NB','Stanford'])\n",
        "df.plot.bar()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAECCAYAAADuGCyPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgphoEtSIf4dynsKAuxXqiQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}